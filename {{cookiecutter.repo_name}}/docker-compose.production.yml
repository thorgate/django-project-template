# Docker-compose configuration for production

version: '3.8'

x-common-spec: &common-spec
  env_file: .env
  restart: unless-stopped

x-django-container-spec: &django-container-spec
  <<: *common-spec
# - {%  if cookiecutter.build_in_ci == YES %}
  image: "${SITE_DJANGO_IMAGE}:${SITE_VERSION}"
# - {%  else %}
  build:
    context: .
    dockerfile: Dockerfile-django.production
# - {%  endif %}
  volumes:
    - "/var/lib/docker-nginx/files/{{cookiecutter.repo_name}}/assets:/files/assets"
    - &django-media-volume "/var/lib/docker-nginx/files/{{cookiecutter.repo_name}}/media:/files/media"
    - &logs-volume "/var/log/{{cookiecutter.repo_name}}:/var/log/{{cookiecutter.repo_name}}"
  networks:
    - default
    - nginx-network
    - postgres-network
  depends_on:
    - redis
  external_links:
    - postgres-{{cookiecutter.postgres_version}}:postgres

services:
  django:
    <<: *django-container-spec
    container_name: {{cookiecutter.repo_name}}_django
    # For some reason the command also has to be specified here, otherwise the entrypoint+command combination won't
    #  work.
    entrypoint: /usr/bin/wait-for-it.sh postgres:5432 -t 60 --
    command: gunicorn {{cookiecutter.default_django_app}}.wsgi:application --workers 2 --bind :80
# - {%  if cookiecutter.frontend_style == SPA %}

  node:
    <<: *common-spec
# -   {%  if cookiecutter.build_in_ci == YES %}
    image: "${SITE_NODE_IMAGE}:${SITE_VERSION}"
# -   {%  else %}
    build:
      context: .
      dockerfile: Dockerfile-node.production
# -   {%  endif %}
    container_name: {{cookiecutter.repo_name}}_node
    command: yarn start
    volumes:
      - "/var/lib/docker-nginx/files/{{cookiecutter.repo_name}}/app/assets:/files/assets"
      - *logs-volume
    networks:
      - default
      - nginx-network
# - {%  endif %}

# - {%  if cookiecutter.include_celery == YES %}
  celery:
    <<: *django-container-spec
    volumes:
      - *django-media-volume
      - *logs-volume
    networks:
      - default
      - postgres-network
    entrypoint: /usr/bin/wait-for-it.sh postgres:5432 -t 60 --
    command: celery --app {{cookiecutter.default_django_app}} worker --autoscale 6,2 --loglevel INFO

  celery_beat:
    <<: *django-container-spec
    container_name: {{cookiecutter.repo_name}}_celery_beat
    volumes:
      - "/var/lib/docker-{{cookiecutter.repo_name}}/celery:/celery"
      - *logs-volume
    networks:
      - default
    depends_on:
      - redis
    # Disable pidfile by specifying an empty one. We used fixed container_name which provides single-running-process
    #  guarantee and the lack of pidfile ensures that Celery Beat starts even if the Docker container was killed and
    #  then restarted (in which case the pidfile would still be present).
    command: celery --app {{cookiecutter.default_django_app}} beat --loglevel INFO --logfile /var/log/{{cookiecutter.repo_name}}/celery-beat.log --pidfile= --schedule /celery/celerybeat-schedule
# - {%  endif %}

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    sysctls:
      # To allow maintaining TCP backlog setting that defaults to 511
      net.core.somaxconn: 512
    volumes:
      - "/var/lib/docker-{{cookiecutter.repo_name}}/redis:/data"
    networks:
      - default

# NB: These networks must be created by ansible and contain the global nginx/postgres containers.
# Keep it in sync with ansible/roles/deploy/tasks/main.yml!
networks:
  default:
    external:
      name: {{cookiecutter.repo_name}}_default
  nginx-network:
    external:
      name: {{cookiecutter.repo_name}}_nginx
  postgres-network:
    external:
      name: {{cookiecutter.repo_name}}_postgres
